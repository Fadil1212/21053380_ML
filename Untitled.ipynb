{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98858ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c780ad83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load independent variables\n",
    "X = pd.read_csv(\"logisticX.csv\")\n",
    "\n",
    "# Load dependent variable\n",
    "y = pd.read_csv(\"logisticY.csv\")\n",
    "\n",
    "\n",
    "data = pd.concat([X, y], axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e6ff86",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.describe())\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cd4886",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb5c1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, learning_rate=0.1, max_iter=10):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iter = max_iter\n",
    "        self.weights = None  # Initialize weights to None\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def cost_function(self, X, y, weights):\n",
    "        m = len(X)\n",
    "        z = np.dot(X, weights)\n",
    "        a = self.sigmoid(z)\n",
    "        cost = -(1/m) * np.sum(y * np.log(a) + (1 - y) * np.log(1 - a))\n",
    "        return cost\n",
    "\n",
    "    def gradient_descent(self, X, y):\n",
    "        m = len(X)\n",
    "        self.weights = np.random.rand(X.shape[1])  # Initialize random weights\n",
    "        costs = []\n",
    "\n",
    "        for iter in range(self.max_iter):\n",
    "            z = np.dot(X, self.weights)\n",
    "            a = self.sigmoid(z)\n",
    "            errors = a - y\n",
    "            gradient = -(1/m) * np.dot(X.T, errors)\n",
    "            self.weights -= self.learning_rate * gradient\n",
    "            cost = self.cost_function(X, y, self.weights)\n",
    "            costs.append(cost)\n",
    "\n",
    "            if iter % 100 == 0:  # Print progress updates every 100 iterations\n",
    "                print(f\"Iteration {iter+1}: Cost = {cost}\")\n",
    "\n",
    "        return costs\n",
    "\n",
    "    def predict(self, X_new):\n",
    "        z = np.dot(X_new, self.weights)\n",
    "        a = self.sigmoid(z)\n",
    "        return np.where(a > 0.5, 1, 0)  # Threshold at 0.5 for binary classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586aa7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(learning_rate=0.1)\n",
    "costs = model.gradient_descent(X_scaled, y)\n",
    "\n",
    "print(f\"Final cost value: {costs[-1]}\")  # Access the last cost after convergence\n",
    "\n",
    "# Use trained weights to find decision boundary (more advanced methods can be used)\n",
    "# ...\n",
    "\n",
    "# Plot decision boundary and data points (code similar to Response B's)\n",
    "# ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4438ad59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models with learning rates 0.1 and 5\n",
    "model_01 = LogisticRegression(learning_rate=0.1)\n",
    "costs_01 = model_01.gradient_descent(X_scaled, y)\n",
    "\n",
    "model_05 = LogisticRegression(learning_rate=5)\n",
    "costs_05 = model_05.gradient_descent(X_scaled, y)\n",
    "\n",
    "# Create the plot (ensure correct iteration limits for convergence)\n",
    "plt.plot(range(100), costs_01[:100], label=\"Learning Rate 0.1\")\n",
    "plt.plot(range(100), costs_05[:100], label=\"Learning Rate 5\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Cost Function\")\n",
    "plt.legend()\n",
    "plt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2368a8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as colors\n",
    "\n",
    "# Assuming 2 classes ('0' and '1')\n",
    "cmap = colors.ListedColormap(['blue', 'orange'])\n",
    "bounds = [-0.5, 0.5, 1.5]  # Adjust according to data range\n",
    "\n",
    "# Create a meshgrid for smooth decision boundary visualization\n",
    "resolution = 500\n",
    "X1, X2 = np.meshgrid(np.linspace(X_scaled[:, 0].min(), X_scaled[:, 0].max(), resolution),\n",
    "                     np.linspace(X_scaled[:, 1].min(), X_scaled[:, 1].max(), resolution))\n",
    "Z = model.predict(np.c_[X1.ravel(), X2.ravel()])\n",
    "Z = Z.reshape(X1.shape)\n",
    "\n",
    "# Plot the contour\n",
    "plt.contourf(X1, X2, Z, cmap=cmap, norm=colors.BoundaryNorm(bounds, cmap.N))\n",
    "\n",
    "# Plot actual data points with different colors for classes\n",
    "plt.scatter(X_scaled[:, 0], X_scaled[:, 1], c=y, cmap=cmap)\n",
    "\n",
    "# Enhance plot visualization (consider these suggestions):\n",
    "plt.title(\"Data Points and Decision Boundary (Learning Rate 0.1)\")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.colorbar(label=\"Predicted Class\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65eaef90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure convergence by training for sufficient iterations\n",
    "max_iter = 1000\n",
    "\n",
    "model_01 = LogisticRegression(learning_rate=0.1, max_iter=max_iter)\n",
    "costs_01 = model_01.gradient_descent(X_scaled, y)\n",
    "\n",
    "model_05 = LogisticRegression(learning_rate=5, max_iter=max_iter)\n",
    "costs_05 = model_05.gradient_descent(X_scaled, y)\n",
    "\n",
    "plt.plot(range(max_iter), costs_01, label=\"Learning Rate 0.1\")\n",
    "plt.plot(range(max_iter), costs_05, label=\"Learning Rate 5\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Cost Function\")\n",
    "plt.legend()\n",
    "plt.title(\"Cost Function vs. Iteration (Max Iterations)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6b7758",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = model_01.predict(X_scaled)  # Use model from Q3 with learning rate 0.1\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# Calculate accuracy, precision, recall, and F1-score\n",
    "accuracy = (cm[0, 0] + cm[1, 1]) / len(y)\n",
    "precision = cm[0, 0] / (cm[0, 0] + cm[0, 1])  # Adjust for class if needed\n",
    "recall = cm[0, 0] / (cm[0, 0] + cm[1, 0])  # Adjust for class if needed\n",
    "f1_score = 2 * precision * recall / (precision + recall)  # Adjust for class if needed\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750e2920",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c anaconda numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c789e58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95b1813",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
